---
title: "final project"
author: "WEITING LIN"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

\newpage

## Abstract

The purpose of this project is to find the critical factors that influence the number neuron spikes, and to fit a model to predict the perceptual decision of the mouse. To achieve the two goals, we first use two-way Anova mixed model to observe the mean firing rate across the visual stimuli levels, and after that we take Logistics Regression Model, also known as Generalized Linear Model, to predict the feedback of mouse selection in each trial.

Before implementing the models, we will do Exploratory Data Analysis and conduct sensitivity analysis to check if two model follow the assumption of homogeneity of variance, and normality assumption after modeling.

## Introduction

According to the article "*Distributed coding of choice, action and engagement across the mouse brain" (2019)* by Steinmetz et al., perceptual decision may include processing sensory information, choosing action, and carry out actions. However, neuronal signals that relate to action do not necessarily relate to choice. For a brain region to get choice-related signals, it must contains neurons that predict the selected action before it occurs. Therefore, we thought neural activities may play a crucial role in the perceptual decision.

To determine the distribution of neurons encoding vision, choice, action, and behavioral engagement, Steinmetz et al and his teams did the experiments on mice to figure out the visual stimuli in response to neural activities around the mouse brain.

The motivations for us to take subset data collected by Steinmetz et al (2019) are to learn more about the correlation between visual stimuli and mouse choice, and to predict that if mouse successfully predict the result of a trial based on the contrast level of visual stimuli.

The key variables in subset data include levels of contrast of right stimulus and left stimulus, and the numbers of spikes of neurons in the visual cortex in unit time (0.4s per trial), feedback of the trials.

In this project, the first primary objective is to realize how do neurons perform in response to visual cortex affected by two stimuli, right contrast levels and left contrast levels, of mice.

The second primary objective is to predict the outcome of each trial with neurons activities and two stimuli, which include right contrast and left contrast. The outcome of each trial will be that mice failed the trial or mice succeeded the trial.

Based on the first primary objective, we will use mixed effect model, two way anova, on this project, and we will set stimulus from right contrast and stimulus of left contrast level as fixed effects, and set session as random effect.

Because we randomly select 5 session out of 39 sessions, this is the reason why we have to set random effect of session.

As for the second primary objective, we will select Logistic regression model to predict the feedback of mouse choice, which is binary.

We believe that the discovery between the neurons activities and behavior choice may advance the principle of neurons that encode behaviorally relevant variables throughout the human brain.

## Background

In the study implemented by Steinmetz et al. (2019), experiments were processed with 10 mice between 11 and 46 weeks and were over 39 session. Steinmetz et al. set up 0.4 time interval for each trial in each session. The mouse was presented with visual stimuli on two screens positioned on either side of it during several hundred trials in each session. The presentation of stimuli was random. Besides, the stimuli have four contrast levels, {0,0.25,0.5,1}, and 0 means no stimuli.

Mouse will control the wheels with their fore paws to make a decision to turn right or turn left or stay still. Mouse could get reward if they turn wheel to the highest contrast side. Besides, if neither stimuli were occurred and mouse keep the wheel still for 1.5s then it could get reward as well.

During the trials, the neuronal activity from 3000 neurons in the visual cortex of the mice was recorded and provided in the form of spike trains, which are collections of timestamps corresponding to neuron firing.

In this project, we utilize subset data from by Steinmetz et al., and focus on experiments of two mice, Cori and Forssmann. We have Cori's data in 12/14/2016, 12/17/2016, 12/18/2016, and have Forssmann's data in 11/01/2017,11/02/2017. Hence, there is five RDS files in this project.

The number of the trials in each the session is bigger than 30, so these five sessions have enough sample number based on statistics requirement.

The each data session consists of following variable:

-   **feedback_type**: type of feedback,

    -   feedback_type=1, means mouse succeeded in the trial

    -   feedback_type=-1, means mouse failed the trial

-   **contrast_left**: contrast of the left stimulus,

-   **contrast_right**: contrast of right stimulus,

-   **spks**: numbers of spikes of neurons in the visual cortex in unit time

-   **time**: centers of the time bins for spks

```{r echo=FALSE, message=FALSE, warning=FALSE}
data_list=list()
for( i in 1:5){
  file_name=paste0("session",i,".rds")
  data_list[[i]]=readRDS(file_name)}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
num_trial_in_each_file=vector()
for(i in 1:5){
  num=length(data_list[[i]]$spks)
  num_trial_in_each_file=append(num_trial_in_each_file,num)
}

trials<-data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_trials=num_trial_in_each_file)

knitr::kable(trials,align="cc",caption="Table 1: number of trials in each file ")
```

## Descriptive analysis

Trials number of each session are different (see Table 1), we have 214, 251, 228, 249, 254 trials in session Cori_12/14, session Cori_12/17, session Cori_12/18, session Forsssmann_11/01, session Forsssmann_11/01 solely.

Neurons number of each session are diverse as well (see Table 2), we have 178, 533, 228, 120, 99 neurons in session Cori_12/14, session Cori_12/17, session Cori_12/18, session Forsssmann_11/01, session Forsssmann_11/01 separately.

```{r echo=FALSE, message=FALSE, warning=FALSE}
num_of_neurons=c()
for(i in 1:5){
  num=dim(data_list[[i]]$spks[[1]])[1]
  num_of_neurons[i]=num
}

num_of_neurons_in_each_file=data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_neurons=num_of_neurons)

knitr::kable(num_of_neurons_in_each_file,align="cc",caption="Table 2: number of Neurons in each trial")
```

### Data pre-processing

Due to the neurons in each session are various (see Table two), we will take the mean firing rate, which is the average rate of neuron spikes per second in each trial.

mean firing rate in each trial:

```{=tex}
\begin{align}

\frac{\text {sum of spikes of all neourns in each trial}}{\text {(total number of neurons in each trial).(total time in 39 time intervals = 0.4s)}}

\end{align}
```
At first, we would like to check if there exists NA values in five sessions (Cori_12/14, Cori_12/17, Cori_12/18, Forssmann_11/01, Forssmann_11/02), and the result shows that it doesn't have NA value. Second, we check the structure of the data, and find that the type of feed back (feedback_type), left contrast levels(contrast_left), right contrast levels (contrast_right) variable are not factor; hence, we will transform them from numeric to factor.

Second, we combine the right contrast level and left contrast level and mean firing data of all session to crate a new data set. Therefore, we got 1196 data from the five sessions (Cori_12/14, Cori_12/17, Cori_12/18, Forssmann_11/01, Forssmann_11/02), which means that there are 1196 trials in five sessions (Cori_12/14, Cori_12/17, Cori_12/18, Forssmann_11/01, Forssmann_11/02).

```{r echo=FALSE, message=FALSE, warning=FALSE}
#to check na
for(i in 1:5){
  print(any(is.na(data_list[[i]])))
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#transform data type
for(i in 1:5){
  data_list[[i]]$feedback_type<-as.factor(data_list[[i]]$feedback_type)
  data_list[[i]]$contrast_left<-as.factor(data_list[[i]]$contrast_left)
  data_list[[i]]$contrast_right<-as.factor(data_list[[i]]$contrast_right)
}

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#new data set
overall_feedback<-c(data_list[[1]]$feedback_type,data_list[[2]]$feedback_typ,data_list[[3]]$feedback_typ,data_list[[4]]$feedback_typ,data_list[[5]]$feedback_typ)

overall_left_contrast<-c(data_list[[1]]$contrast_left,data_list[[2]]$contrast_left,data_list[[3]]$contrast_left,data_list[[4]]$contrast_left,data_list[[5]]$contrast_left)

overall_right_contrast<-c(data_list[[1]]$contrast_right,data_list[[2]]$contrast_right,data_list[[3]]$contrast_right,data_list[[4]]$contrast_right,data_list[[5]]$contrast_right)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#mean firing rate in 5 session
avg_firing_rate=c()
num=1
for(i in 1:5){
  trial=length(data_list[[i]]$spks)
  for(j in 1:trial){
    neurons=dim(data_list[[i]]$spks[[j]])[1]
    avg_firing_rate[num]=sum(data_list[[i]]$spks[[j]])/neurons/0.4
    num=num+1
  }
}
```

The new data will contain 5 columns, which are feedback of a trial (feedback), contrast of the left stimulus in each trial (contrast_left), contrast of the left stimulus in each trial (contrast_right), and mean firing rate of in each trial (avg_firing_rate), and corresponding session of each trial (session).

From the plot below, we could find that distribution in average firing rate in session 5 may have Chi-squared distribution, and distributions of others are more likely to have normal distribution.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#create new data including feedback, left contrast level, right contrast leverl, average #firing rate across each trial in five files
library(ggplot2)
#install.packages("hrbrthemes")
#install.packages("rlang")
library(rlang)
library(hrbrthemes)
library(dplyr)
library(tidyr)
library(viridis)
new_data<-data.frame(feedback=overall_feedback,contrast_left=overall_left_contrast,contrast_right=overall_right_contrast,avg_firing_rate=avg_firing_rate,session=c(rep("session 1",214),rep("session 2",251),rep("session 3",228),rep("session 4",249),rep("session 5",254)))
new_data$session<-as.factor(new_data$session)
#head(new_data)
p2 <- ggplot(data=new_data, aes(x=avg_firing_rate, group=session, fill=session)) +
    geom_density(adjust=1.5, alpha=.4) +
    theme_ipsum()
p2
```

### Feedback of each session

After data pre-processing, we would like yo heck the success rate, mouse succeeded to turn the wheel to the right sides, in each session. Hence, we do some calculation on feedback. The table below (Table 3) shows that 5 sessions do not have too much difference in success rate, all of them are around 65% to 66%.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
library(pander)
#xtabs(~overall_left_contrast+overall_right_contrast,data=new_data)
new_data%>%group_by(session)%>%summarise(success_rate=paste0(round(sum(feedback==1)*100/length(feedback),2),"%"))->success
pander(success,caption="Table 3: success rate in each session",justify="center")
```

### Activities of each neuron per second in first trial and last trial among five sessions

Due to the reason the difference neurons number in five session, we would like to find out if there exist some special phenomenon in the five session. Hence, we plot the average firing rate of each neuron per second in the first trial and in last trial among five sessions.

average firing rate of each neuron per second per trial:

```{=tex}
\begin{align}

\frac{\text {sum of spikes for each neourn in each trial}}{\text {(total time in 39 time intervals)}}

\end{align}
```
We are curious about the activities of each neuron from each session. However, the trials in each session are numerous, which may influence the visualization of the activities of each neuron in each trail, so we only take the first trial and last trial in each session to find out if there exist special pattern of activities of neuron.

From the histogram plots below, we find out that the activities of neurons will drop down in last trail of each session, which mean that the number of spikes in 0 increase. Besides, we also observe that the maximum number of spikes in first trial is bigger than the maximum one in last trial, except in session five (see Table 4). Hence, we deduce that the performance of the neuron will decrease over time. In other words, the concentration of mouse decreases over extensive trials.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
neuron_trial<-function(x,y){
  a=c()
  for(i in y){
    a=append(a,rowSums(data_list[[x]]$spks[[i]]))
  }
  return(a)
}
compare=function(x=session,y=neuron,z=trial){
  index=c(rep("last trial",y),rep("first trial",y))
  level_order=c("last trial","first trial")
  index=factor(index,level=level_order)
  newd=data.frame(index=index,firing_rate=c(neuron_trial(x,z),neuron_trial(x,1)))
  ggplot(newd, aes(x=firing_rate, color=index)) + geom_histogram(fill="white",alpha=.3,position="identity")+xlab(paste0("session",x))+ylab("neurons count")
}


first_trial=c(max(neuron_trial(1,1)),max(neuron_trial(2,1)),max(neuron_trial(3,1)),max(neuron_trial(4,1)),max(neuron_trial(5,1)))

last_trial=c(max(neuron_trial(1,214)),max(neuron_trial(2,251)),max(neuron_trial(3,228)),max(neuron_trial(4,249)),max(neuron_trial(5,254)))

session=c("session 1","session 2","session 3","session 4","session 5")

pander(data.frame(session=session,first_trial=first_trial,last_trial=last_trial),caption="Table 4 : maximum number of spikes in first trial and last trial in each session",justify="center")
```

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#require(gridExtra)
#install.packages("gridExtra")
library("gridExtra")
par(mfrow=c(3,2))
plot1<-compare(1,178,214)
plot2<-compare(2,533,251)
plot3<-compare(3,228,228)
plot4<-compare(4,120,249)
plot5<-compare(5,99,254)
grid.arrange(plot1, plot2,plot3,plot4,plot5,ncol=2)

```

### Main effect from left contrast levels and right contrast levels

We are curious about that if the same levels of contrast of two sides, left and right, have the same effect on mean firing rate of mice; therefore, we take the mean plots of two sides contrast levels over 5 sessions to find out the influence on mean firing rate.

From the figure 1, we could observe contrast of left stimulus has the highest mean firing rate when contrast level at 0.05 rather than level at 1, and has the lowest mean firing rate when contrast level at 0.25.

From the figure 2, the mean firing rate from contrast of right stimulus would have the lowest value when contrast level at 0.25, and have the highest value when contrast level at 1.

Despite the fact that both sides have the lowest mean firing rate value at level 0.25, the stimuli from both sides still have the different mean firing rate at the same contrast levels.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
library(gplots)
par(mfrow=c(1,2))
plotmeans(avg_firing_rate~contrast_left,data=new_data,xlab = "left contrast levels",ylab="mean firing rate",main="figure 1: Main effect from left contrast stimulus",cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data,xlab="right contrast levels",ylab="mean firing rate",main="figure 2: Main effect from right contrast stimulus",cex.main=0.8)
```

After taking a look at mean plots of two sides contrast levels over five sessions, we are interested in if the main effect of two sides contrast levels has the similar corresponding mean firing rate in each sessions.

From the plots below (figure 3 to figure 8), we find that except session 1, the highest mean firing rate occurs when contrast level of right stimulus at 1 . However, the highest mean firing rate in response to left stimulus is either at contrast level 0.25 or at contrast level 0.5 in each session.

Overall, the main effects from two side stimuli in each session share diverse effect in mean firing rate.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(1,2))
for(i in 1:5){
  name=paste0("session ",i)
plotmeans(avg_firing_rate~contrast_left,data=new_data[new_data$session==name,],xlab = "left contrast levels",ylab="mean firing rate",main=paste0("figure ",i+2,": Main effect of left contrast stimulus"),cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data[new_data$session==name,],xlab="right contrast levels",ylab="mean firing rate",main=paste0("figure ",i+3,": Main effect of right contrast stimulus"),cex.main=0.8)
mtext(paste0("session",i),side = 3,line = -0.79,cex=1,outer = TRUE)
      
}

```

### Interaction effect between left side contrast levels and right side contrast levels

Due to the reason that mouse got the two sides stimuli at the same time, we consider that the interaction effect between right side contrast levels (contrast_right) and left side contrast levels (contrast_left) may affect the mean firing rate. Hence, we do interaction plot to see if the interaction effect exists.

From the figure 3, we could learn that there exists the interaction effect between left side contrast levels and right side contrast levels. Because the lines in the figure 3, combinations of left side contrast levels and right side contrast levels, cross.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
interaction.plot(new_data$contrast_left,new_data$contrast_right,new_data$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main="figure 9: interaction effect between right contrast levels and left contrast levels",cex.main=0.8)
```

We would like to know that if any session exists interaction effect between two sides contrast levels. From figure 10 to figure 14, the four lines in each plot intercept. Therefore, it is obvious that each session has interaction effect, which may influence mean firing rate.

Based on the result above, we will test if interaction effect is significant in interpretation of the mean firing rate in following inferential analysis.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(2,1))
#par(mar = c(1, 1, 1, 1))
for(i in 1:5){
  name=paste0("session ",i)
  interaction.plot(new_data[new_data$session==name,]$contrast_left,new_data[new_data$session==name,]$contrast_right,new_data[new_data$session==name,]$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main=paste0("figure ",i+9,": interaction effect of session",i,": right contrast levels and left contrast levels"),cex.main=0.8)
}

```

## Inferential analysis

### Mixed effect model-Two way ANOVA

Because we have no whole plot split factor in this model, we focus on two way anova model with fixed effect of two contrast levels variable, and one random effect of session. We will use type III anova due to the reasaon that we assume that interaction effect is significant.

$Y_{ijkl}=\mu_{....}+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\gamma_l+\epsilon_{ijkl}$ i=1,2,3,4 j=1,2,3,4 k=1..$n_{ijl}$, l=1,2,3,4,5

-   $Y_{ijkl}$: refer to the $k^{th}$ mean firing rate in $l^{th}$ session across $i^{th}$ left contrast level and $j^{th}$ right contrast level.

-   $\mu_{….}$ is the overall mean firing rate across all trials in five sessions.

-   $\alpha_i$ refers to the $i^{th}$ left side contrast level, and $\alpha_i$ is fixed effect so $\sum_{i=1}^{4}\alpha_i=0$.

    -   i=1: left side contrast level=0

    -   i=2: left side contrast level=0.25

    -   i=3: left side contrast level=0.5

    -   i=4: left side contrast level=1

-   $\beta_j$ refers to the $j^{th}$ right side contrast level, and $\beta_j$ is fixed effect so $\sum_{j=1}^{4}\beta_j=0$.

    -   j=1: right side contrast level=0

    -   j=2: right side contrast level=0.25

    -   j=3: right side contrast level=0.5

    -   j=4: right side contrast level=1

-   $(\alpha\beta)_{ij}$ refers to the interaction effect between $j^{th}$ right contrast level and $i^{th}$ left contrast level, and there will be 16 kinds of combination of two sides contrast levels.$\sum_{i=1}^{4}(\alpha\beta)_{ij}=0, \sum_{j=1}^{4}(\alpha\beta)_{ij}=0$.

-   $\gamma_l$ refers to the $l^{th}$ session, and$\gamma_l$ is random effect, $\gamma_l\sim N(0,\sigma_{\gamma})$.

    -   l=1: session 1

    -   l=2: session 2

    -   l=3: session 3

    -   l=4: session 4

    -   l=5: session 5

-   $\epsilon_{ijkl}$: refer to the residual of mean firing rate of $k^{th}$ trial in $l^{th}$ session across $i^{th}$ left contrast level and $j^{th}$ right contrast level in, $\epsilon_{ijkl}$ i.i.d $N(0,\sigma^2)$.

From the Anova table (Table 5) below, we could found that the interaction effect is slightly significant due to the reason that its p-value, 0.04353, smaller than 0.05. Furthermore, the p-value for contrast of left stimulus and contrast of right stimulus are 9.737x$10^{-5}$ and 4.806x$10^{-7}$ separately.

We also could learn that the both contrast of the right stimulus and contrast of left stimulus have a the strong influence in mean firing rate since either of them has p-value smaller than 0.001. Besides, proportion of variability that is due to variability in session is 76.02%, which is calculated from $\sigma_{\gamma}/(\sigma_{\gamma}+\sigma)$.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#install.packages("car")
library("lme4")
library(pander)
#install.packages("lmerTest")
library("lmerTest")
library(car)
library(carData)
options(contrasts = c("contr.treatment", "contr.poly"))
fit.full <- lmer(avg_firing_rate ~ contrast_left+contrast_right+contrast_left*contrast_right+(1|session), data=new_data)
#summary(fit_full)
pander(anova(fit.full),caption = "Table 5: Type III Analysis of Variance Table with Satterthwaite's method (continued below)",justify="center")
#proportion=(126.67/(126.67+39.95))
```

#### Hypothesis: Reduced model versus Full model

$H_0: (\alpha\beta)_{ij}$ does not exist.

$H_1: (\alpha\beta)_{ij}$ exists.

we will use F-test, based on the hypotheses above, to see if interaction effect between right contrast level and left contrast level exist. The result show that its p-value small (\<0.05) to reject null hypothesis; hence, we conclude that $(\alpha\beta)_{ij}$ exists. In the other words, we will keep interaction effect in the model.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(pander)
fit.reduced<-lmer(avg_firing_rate ~contrast_left+contrast_right+(1|session), data=new_data)
#(step_res <- step(fit.full))
#final <- get_model(step_res)
#a<-anova(final)
anova(fit.full,fit.reduced)
```

#### Estimated coefficients of $\alpha_i,\beta_j,(\alpha\beta)_{ij}$

After selecting the model, full model including interaction, we are going to calculate the estimated coefficients of the model.

$\hat \alpha_i = \bar Y_{i...}-\bar Y_{....},\space i=1,2,3,4 \\ \hat \beta_j = \bar Y_{.j..}-\bar Y_{....},\space j=1,2,3,4 \\ \widehat {(\alpha\beta)_{ij}} = \bar Y_{ij..}-(\bar Y_{....}+\hat \alpha_i+\beta_j), i=1,2,3,4,\space j=1,2,3,4$

-   $\hat \alpha_i$ refers to the estimated coefficient of $i^{th}$contrast level of left stimulus,

    -   i=1: contrast level of left stimulus will be 0

    -   i=2: contrast level of left stimulus will be 0.25

    -   i=3: contrast level of left stimulus will be 0.5

    -   i=4: contrast level of left stimulus will be 1

-   $\hat \beta_j$ refers to the estimated coefficient of $j^{th}$contrast of right stimulus,

    -   j=1: contrast level of right stimulus will be 0

    -   j=2: contrast level of right stimulus will be 0.25

    -   j=3: contrast level of right stimulus will be 0.5

    -   j=4: contrast level of right stimulus will be 1

-   $\widehat {(\alpha\beta)_{ij}}$ refers to the estimated coefficient on $i^{th}$contrast of left stimulus and $j^{th}$contrast of right stimulus

From the Table 6, Table 7, Table 8, we could learn the estimated coefficients of $\alpha_i, \beta_j,(\alpha\beta)_{ij}$ across the two sides contrast levels, which contain {0,0.25,0.5,1}.

```{r echo=FALSE, message=FALSE, warning=FALSE}
contrast_left=c()
for(i in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
  contrast_left<-append(contrast_left,ans)
}

contrast_right=c()
for(j in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
  contrast_right<-append(contrast_right,ans)
}

interaction_effect=c()
for(i in c(0,0.25,0.5,1)){
  for(j in c(0,0.25,0.5,1)){
    alpha<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
    beta<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
    ans<-mean(new_data[new_data$contrast_left==i&new_data$contrast_right==j,4])-(mean(new_data$avg_firing_rate)+alpha+beta)
    interaction_effect<-append(interaction_effect,ans)
  }
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
pander(data.frame(i=c(1,2,3,4),left_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_left),caption = "Table 6: estimated alpha_i",justify="center")
pander(data.frame(j=c(1,2,3,4),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_right),caption = "Table 7: estimated beta_j",justidy="center")
pander(data.frame(i=c(rep(1,4),rep(2,4),rep(3,4),rep(4,4)),j=rep(c(1,2,3,4),4),left_contrast_level=c(rep(0,4),rep(0.25,4),rep(0.5,4),rep(1,4)),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha_beta=interaction_effect),caption = "Table 8: estimated interaction effect",justify="center")
```

### Logistics regression model

Due to the result of feedback variable is binary, trial outcome is either failed (feedback=1) or succeeded (feedback=-1), we use Logistics regression model to predict the feedback, which is the outcome that if mouse chooses the correct side with the strong contrast level.

We also have interest in that if the reduced model is better than full model. The factors in reduced model contain contrast of right stimulus and contrast of left stimulus, and factors in full model include all factors in reduced model and interaction factor between contrast of right stimulus and contrast of left stimulus.

The reason why we do not consider the average firing rate of each neuron per second across trials into the model is because we have known mouse will reduce it attentiveness over trials, so if we use this kind of information into model, it may mislead the prediction result.

Moreover, the neuron number are various in each session, so we use the mean firing rate across each session and each trial as the explanatory variable in this model.

#### Data Pre-processing

we would like to change the value of feedback, because Logistics regression model requests response value should in {0,1}. As a result, we will transform feedback value to 0 when feedback value is -1, and keep other feedback values as 1.

Table 9 indicated the levels of feedback, and number of two levels, 0 and 1, after data pre-processing.

We also have to split our dataset into training dataset and testing dataset, in this part, we set first 100 dataset as testing data and remaining dataset containing 1096 trials as training data.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
levels(new_data$feedback)[levels(new_data$feedback)=="-1"]<-"0"
ans<-data.frame(table(new_data$feedback))
colnames(ans)<-c("level","count")
pander(ans,caption="Table 9: the levels of feedback and the corresponding numer of each level",justify="center")
train<-new_data[101:1196,]
test<-new_data[1:100,-1]
```

#### Hypothesis: Reduced model versus Full model

$H_0: \beta_{ij}=0$, for i=1,2,3,4, j=1,2,3,4

$H_1:$ at least one $\beta_{ij}\neq0$ , for i=1,2,3,4, j=1,2,3,4

$\beta_{ij}$ refer to the coefficient of interaction from $i^{th}$ level of contrast of left stimulus and $j^{th}$ level of contrast from right stimulus.

To find out which model is better we use Likelihood Ratio Test to determine the result. The result indicated that model with interaction is better, which means we will reject null hypothesis, because the p-value (0.9226x$10^{-3}$) is smaller than 0.01. Besides, the AIC of full model is 1380.1 which is smaller than reduced model, whose AIC is 1390.1. Therefore, we could conclude that full model with interaction is more appropriate.

```{r echo=FALSE, message=FALSE, warning=FALSE}
predict.full<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)

predict.reduce<-glm(feedback~contrast_left+contrast_right+avg_firing_rate,family=binomial,data=train)
#summary(predict.reduce)
anova(predict.reduce,predict.full,test="LRT")
```

The GLM model will be the formula below.

```{=tex}
\begin{align} \text{logit{P(feedback is 1)}}=\beta_0+\sum_{i=2}^{4}\beta_{1i}X_{1i}+\sum_{j=2}^{4}\beta_{2j}X_{2j}+\beta_3X_3+\sum_{i=2}^{4}\sum_{j=2}^{4}\beta_{5ij}X_{5ij}\end{align}
```
$\beta_{1i}$ represents the coefficients of $i^{th}$ left contrast level, $\beta_{2j}$ represents the coefficients of $j^{th}$ right contrast level, $\beta_3$ represents the coefficient of mean firing rate, $\beta_{5ij}$ represents the coefficient of interaction at $i^{th}$ left contrast level and $j^{th}$ right contrast level.

The corresponding contrast level of i={1,2,3,4} and j={1,2,3,4} is {0,0.25,0.5,1}.

The corresponding estimated coefficients of factors in GLM are presented in Table 10. The reason that why the estimated coefficients for contrast level including 0, which means either i or j is denoted as 1, in each side disappear is because we take them as baseline for other contrast levels.

Due to the positive coefficient of $X_{avg \space firing \space rate}$, we are able to say that the average firing rate will have positive influence in choosing the right direction and higher probability to get the success in a trial.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
ans<-summary(model)
#ans
result<-data.frame(ans$coefficients[,1])
colnames(result)<-"estimated coefficient"
pander(head(result,5),caption="Table 10: first 5 estimated coeffecicient of GLM model",justify="center")
```

#### Prediction

The confusion matrix will be below matrix :

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
model_train<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
threshold<-0.5
predict_value<-ifelse(predict(model_train,test)>threshold,1,0)
actual_value<-new_data$feedback[1:100]
table(predict_value,actual_value)
```

From the Table 11, it show sensitivity, specificity, and accuracy rate from the prediction result.

-   Sensitivity: also called true positive rate which is the probability of a positive test result.

    -   Formula: $\frac{True\space Positive}{True\space Positive+False\space Negative}=\frac{12}{62+12}$

-   Specificity: also known as true negative rate, which the probability of a negative test result.

    -   Formula: $\frac{True \space Negative}{True \space Negative+False\space Positive}=\frac{3}{23+3}$

-   Accuracy: refer to the probability that model predict the correct feedback.

    -   Formula: $\frac{True \space Negative+True \space Positive}{True \space Negative+True \space Positive+False\space Positive+False\space Negative}=\frac{65}{65+35}$

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
pander(data.frame(Sensitivity=paste0(round(12*100/(12+62),2),"%"),Specificity=paste0(round(300/(23+3),2),"%"),Accuracy=paste0(round(65*100/(65+35),2),"%")),caption = "Table 11",justify="center")
```

## Sensitive analysis

### Sensitive analysis for two anova model

#### Assumption: Normality

In figure 15, the QQ-plot shows that there has heavy tail, and some outliers, which are labeled with corresponding session. Overall, it is still obviously that the distribution of data are follow the diagonal line. Hence, we conclude that the data has normality.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#install.packages("lattice")
library(lattice)
#qqnorm(resid(fit.full))
qqmath(fit.full, id=0.05, main="figur 15: QQ-plot")#id:outlier
```

#### Outliers proportion

In general rule to investigate outlier is that any point that is more than 3 times the mean of all the cook's distances. Hence, we will use this principle to find out the outlier based on the mixed model. After calculation, there is 8.9% of data is outlier based on the mixed model.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
cooksD <- cooks.distance(fit.full)
influential <- cooksD[(cooksD > (3 * mean(cooksD, na.rm = TRUE)))]
#influential
infp<-which(cooksD > (3 * mean(cooksD, na.rm = TRUE)))
plot(cooksD)
points(infp,cooksD[infp],pch=17,col="red",cex=1.1)
proportion_out=length(infp)/length(cooksD)
#proportion_out
```

#### Assumption: **Homogeneity of Variance**

We would like to determine if the mixed model follow homogeneity of variance, and the plot below (fig 16) show that the residuals are not symmetric to the line: y=0. Hence we conclude that the model violate the homogeneity of variance.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
plot(fit.full,main="figure 16: fitted value versus residual",xlab="fitted value",ylab = "residual")

```

We also take a look at the residual versus fitted plot in each session, and we found that all of them do not scatter evenly around the horizontal line (y=0), which means that they do not follow homogeneity of variance. However, we could find an interesting situation, the tendency of the scatter plots will go down slowly, especially in session five, session three. Therefore, we consider that the mouse may drift off when they have done too much trials.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#install.packages("lme4")
library(lme4)
new_data$res<-residuals(fit.full)
plot(fit.full, resid(.) ~ fitted(.) | session )

```

### Sensitive analysis for GLM model

#### Pearson residuals and deviance residuals

The purpose of this part is to make sure that the model would not have the problem regarding potential lack-of-fit, which may occur when pearson residuals and deviance residuals are not quite similar. The boxplot showed below indicates that the distributions of two residuals are similar, so there does not have lack-of-fit issue.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
res.P = residuals(model, type = "pearson")
res.D = residuals(model, type = "deviance")
boxplot(cbind(res.P, res.D), names = c("Pearson", "Deviance"))
```

#### Residuals plots

To make sure that there does not leave any systematic patterns in residuals.

The red curves are close to 0 in the two plots, but it may exisit a quadratic pattern. Higher order terms can be added to check if the pattern exists.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(1,2))
plot(model$fitted.values, res.P, pch=16, cex=0.6, ylab='Pearson Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.P, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
plot(model$fitted.values, res.D, pch=16, cex=0.6, ylab='Deviance Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.D, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
```

#### Leverage points

We use it to find the influential points in data, and find that the influential points account for 16.87% of data points.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(1,1))
leverage = hatvalues(model)
plot(names(leverage), leverage, xlab="Index", type="h")
points(names(leverage), leverage, pch=16, cex=0.6)
p = length(coef(model))
n = nrow(new_data)
h=2*p/n
proportion=length(which(leverage>h))/length(leverage)
#proportion
abline(h=2*p/n,col=2,lwd=2,lty=2)
```

## Alternative methods

### Redres packages

we could use redres package to find out the residuals plot of mixed model with lmer in html.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#install.packages("remotes")
#remotes::install_github("goodekat/redres")
#library(redres)
#launch_redres(fit.full)
```

## Conclusion

From the analysis above, we learn that the neuron spikes will become not active if we did too much trials. Besides, we do not have the detailed information regarding the neuron type; hence, it is hard for us to make the comprehensive cluster analysis regarding the pattern of neurons.

We also find a paper launched by Macknik SL, and Livingstone MS mentioned that *"A brief visual target stimulus may be rendered invisible if it is immediately preceded or followed by another stimulus."(1998, Neuronal correlates of visibility and invisibility in the primate visual system.).* Therefore, it is reasonable to explain why the neuron spikes become less over plentiful trials.

Hence, we think that if we have to do the similar experiment, relation between visual stimuli and neuron spikes, once again, we have to take the time interval between stimuli into consideration. Perhaps, the result of neuron spikes would be different.

## Appendix

### Reference

1.  *Distributed coding of choice, action and engagement across the mouse brain" (2019, Steinmetz et al.)*
2.  *Neuronal correlates of visibility and invisibility in the primate visual system (1998, Macknik SL, and Livingstone MS)*
3.  STA 207 Statistical Methods for Research II, Winter 2023

### **Code**

<https://github.com/wINdy0908/207_final_project_weiting_lin/blob/main/final_project_code.R>

```{r eval=FALSE, include=FALSE}
data_list=list()
for( i in 1:5){
  file_name=paste0("session",i,".rds")
  data_list[[i]]=readRDS(file_name)}

##
library(ggplot2)
num_trial_in_each_file=vector()
for(i in 1:5){
  num=length(data_list[[i]]$spks)
  num_trial_in_each_file=append(num_trial_in_each_file,num)
}

trials<-data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_trials=num_trial_in_each_file)

knitr::kable(trials,align="cc",caption="Table 1: number of trials in each file ")

##
num_of_neurons=c()
for(i in 1:5){
  num=dim(data_list[[i]]$spks[[1]])[1]
  num_of_neurons[i]=num
}

num_of_neurons_in_each_file=data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_neurons=num_of_neurons)

knitr::kable(num_of_neurons_in_each_file,align="cc",caption="Table 2: number of Neurons in each trial")

##
#to check na
for(i in 1:5){
  print(any(is.na(data_list[[i]])))
}

##
#transform data type
for(i in 1:5){
  data_list[[i]]$feedback_type<-as.factor(data_list[[i]]$feedback_type)
  data_list[[i]]$contrast_left<-as.factor(data_list[[i]]$contrast_left)
  data_list[[i]]$contrast_right<-as.factor(data_list[[i]]$contrast_right)
}

##
#new data set
overall_feedback<-c(data_list[[1]]$feedback_type,data_list[[2]]$feedback_typ,data_list[[3]]$feedback_typ,data_list[[4]]$feedback_typ,data_list[[5]]$feedback_typ)

overall_left_contrast<-c(data_list[[1]]$contrast_left,data_list[[2]]$contrast_left,data_list[[3]]$contrast_left,data_list[[4]]$contrast_left,data_list[[5]]$contrast_left)

overall_right_contrast<-c(data_list[[1]]$contrast_right,data_list[[2]]$contrast_right,data_list[[3]]$contrast_right,data_list[[4]]$contrast_right,data_list[[5]]$contrast_right)

##
avg_firing_rate=c()
num=1
for(i in 1:5){
  trial=length(data_list[[i]]$spks)
  for(j in 1:trial){
    neurons=dim(data_list[[i]]$spks[[j]])[1]
    avg_firing_rate[num]=sum(data_list[[i]]$spks[[j]])/neurons/0.4
    num=num+1
  }
}

##
#create new data including feedback, left contrast level, right contrast leverl, average #firing rate across each trial in five files
library(ggplot2)
#install.packages("hrbrthemes")
#install.packages("rlang")
library(rlang)
library(hrbrthemes)
library(dplyr)
library(tidyr)
library(viridis)
new_data<-data.frame(feedback=overall_feedback,contrast_left=overall_left_contrast,contrast_right=overall_right_contrast,avg_firing_rate=avg_firing_rate,session=c(rep("session 1",214),rep("session 2",251),rep("session 3",228),rep("session 4",249),rep("session 5",254)))
new_data$session<-as.factor(new_data$session)
#head(new_data)
p2 <- ggplot(data=new_data, aes(x=avg_firing_rate, group=session, fill=session)) +
    geom_density(adjust=1.5, alpha=.4) +
    theme_ipsum()
p2

##
library(pander)
#xtabs(~overall_left_contrast+overall_right_contrast,data=new_data)
new_data%>%group_by(session)%>%summarise(success_rate=paste0(round(sum(feedback==1)*100/length(feedback),2),"%"))->success
pander(success,caption="Table 3: success rate in each session",justify="center")

##
neuron_trial<-function(x,y){
  a=c()
  for(i in y){
    a=append(a,rowSums(data_list[[x]]$spks[[i]]))
  }
  return(a)
}
compare=function(x=session,y=neuron,z=trial){
  index=c(rep("last trial",y),rep("first trial",y))
  level_order=c("last trial","first trial")
  index=factor(index,level=level_order)
  newd=data.frame(index=index,firing_rate=c(neuron_trial(x,z),neuron_trial(x,1)))
  ggplot(newd, aes(x=firing_rate, color=index)) + geom_histogram(fill="white",alpha=.3,position="identity")+xlab(paste0("session",x))+ylab("neurons count")
}


first_trial=c(max(neuron_trial(1,1)),max(neuron_trial(2,1)),max(neuron_trial(3,1)),max(neuron_trial(4,1)),max(neuron_trial(5,1)))

last_trial=c(max(neuron_trial(1,214)),max(neuron_trial(2,251)),max(neuron_trial(3,228)),max(neuron_trial(4,249)),max(neuron_trial(5,254)))

session=c("session 1","session 2","session 3","session 4","session 5")

pander(data.frame(session=session,first_trial=first_trial,last_trial=last_trial),caption="Table 4 : maximum number of spikes in first trial and last trial in each session",justify="center")

##
#require(gridExtra)
#install.packages("gridExtra")
library("gridExtra")
par(mfrow=c(3,2))
plot1<-compare(1,178,214)
plot2<-compare(2,533,251)
plot3<-compare(3,228,228)
plot4<-compare(4,120,249)
plot5<-compare(5,99,254)
grid.arrange(plot1, plot2,plot3,plot4,plot5,ncol=2)

##
library(gplots)
par(mfrow=c(1,2))
plotmeans(avg_firing_rate~contrast_left,data=new_data,xlab = "left contrast levels",ylab="mean firing rate",main="figure 1: Main effect from left contrast stimulus",cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data,xlab="right contrast levels",ylab="mean firing rate",main="figure 2: Main effect from right contrast stimulus",cex.main=0.8)

##
par(mfrow=c(1,2))
for(i in 1:5){
  name=paste0("session ",i)
plotmeans(avg_firing_rate~contrast_left,data=new_data[new_data$session==name,],xlab = "left contrast levels",ylab="mean firing rate",main=paste0("figure ",i+2,": Main effect of left contrast stimulus"),cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data[new_data$session==name,],xlab="right contrast levels",ylab="mean firing rate",main=paste0("figure ",i+3,": Main effect of right contrast stimulus"),cex.main=0.8)
mtext(paste0("session",i),side = 3,line = -0.79,cex=1,outer = TRUE)
}

##
interaction.plot(new_data$contrast_left,new_data$contrast_right,new_data$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main="figure 9: interaction effect between right contrast levels and left contrast levels",cex.main=0.8)

##
par(mfrow=c(2,1))
#par(mar = c(1, 1, 1, 1))
for(i in 1:5){
  name=paste0("session ",i)
  interaction.plot(new_data[new_data$session==name,]$contrast_left,new_data[new_data$session==name,]$contrast_right,new_data[new_data$session==name,]$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main=paste0("figure ",i+9,": interaction effect of session",i,": right contrast levels and left contrast levels"),cex.main=0.8)
}

##
#install.packages("car")
library("lme4")
library(pander)
#install.packages("lmerTest")
library("lmerTest")
library(car)
library(carData)
options(contrasts = c("contr.treatment", "contr.poly"))
fit.full <- lmer(avg_firing_rate ~ contrast_left+contrast_right+contrast_left*contrast_right+(1|session), data=new_data)
#summary(fit_full)
pander(anova(fit.full),caption = "Table 5: Type III Analysis of Variance Table with Satterthwaite's method (continued below)",justify="center")
#proportion=(126.67/(126.67+39.95))

##
library(pander)
fit.reduced<-lmer(avg_firing_rate ~contrast_left+contrast_right+(1|session), data=new_data)
#(step_res <- step(fit.full))
#final <- get_model(step_res)
#a<-anova(final)
anova(fit.full,fit.reduced)

##
contrast_left=c()
for(i in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
  contrast_left<-append(contrast_left,ans)
}

contrast_right=c()
for(j in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
  contrast_right<-append(contrast_right,ans)
}

interaction_effect=c()
for(i in c(0,0.25,0.5,1)){
  for(j in c(0,0.25,0.5,1)){
    alpha<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
    beta<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
    ans<-mean(new_data[new_data$contrast_left==i&new_data$contrast_right==j,4])-(mean(new_data$avg_firing_rate)+alpha+beta)
    interaction_effect<-append(interaction_effect,ans)
  }
}

##
pander(data.frame(i=c(1,2,3,4),left_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_left),caption = "Table 6: estimated alpha_i",justify="center")
pander(data.frame(j=c(1,2,3,4),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_right),caption = "Table 7: estimated beta_j",justidy="center")
pander(data.frame(i=c(rep(1,4),rep(2,4),rep(3,4),rep(4,4)),j=rep(c(1,2,3,4),4),left_contrast_level=c(rep(0,4),rep(0.25,4),rep(0.5,4),rep(1,4)),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha_beta=interaction_effect),caption = "Table 8: estimated interaction effect",justify="center")

##
levels(new_data$feedback)[levels(new_data$feedback)=="-1"]<-"0"
ans<-data.frame(table(new_data$feedback))
colnames(ans)<-c("level","count")
pander(ans,caption="Table 9: the levels of feedback and the corresponding numer of each level",justify="center")
train<-new_data[101:1196,]
test<-new_data[1:100,-1]

##
predict.full<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)

predict.reduce<-glm(feedback~contrast_left+contrast_right+avg_firing_rate,family=binomial,data=train)
#summary(predict.reduce)
anova(predict.reduce,predict.full,test="LRT")

##
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
ans<-summary(model)
#ans
result<-data.frame(ans$coefficients[,1])
colnames(result)<-"estimated coefficient"
pander(head(result,5),caption="Table 10: first 5 estimated coeffecicient of GLM model",justify="center")

##
model_train<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
threshold<-0.5
predict_value<-ifelse(predict(model_train,test)>threshold,1,0)
actual_value<-new_data$feedback[1:100]
table(predict_value,actual_value)

##
pander(data.frame(Sensitivity=paste0(round(12*100/(12+62),2),"%"),Specificity=paste0(round(300/(23+3),2),"%"),Accuracy=paste0(round(65*100/(65+35),2),"%")),caption = "Table 11",justify="center")

##
#install.packages("lattice")
library(lattice)
#qqnorm(resid(fit.full))
qqmath(fit.full, id=0.05, main="figur 15: QQ-plot")#id:outlier

##
cooksD <- cooks.distance(fit.full)
influential <- cooksD[(cooksD > (3 * mean(cooksD, na.rm = TRUE)))]
#influential
infp<-which(cooksD > (3 * mean(cooksD, na.rm = TRUE)))
plot(cooksD)
points(infp,cooksD[infp],pch=17,col="red",cex=1.1)
proportion_out=length(infp)/length(cooksD)
#proportion_out

##
plot(fit.full,main="figure 16: fitted value versus residual",xlab="fitted value",ylab = "residual")

##
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
res.P = residuals(model, type = "pearson")
res.D = residuals(model, type = "deviance")
boxplot(cbind(res.P, res.D), names = c("Pearson", "Deviance"))

##
par(mfrow=c(1,2))
plot(model$fitted.values, res.P, pch=16, cex=0.6, ylab='Pearson Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.P, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
plot(model$fitted.values, res.D, pch=16, cex=0.6, ylab='Deviance Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.D, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')


##
par(mfrow=c(1,1))
leverage = hatvalues(model)
plot(names(leverage), leverage, xlab="Index", type="h")
points(names(leverage), leverage, pch=16, cex=0.6)
p = length(coef(model))
n = nrow(new_data)
h=2*p/n
proportion=length(which(leverage>h))/length(leverage)
#proportion
abline(h=2*p/n,col=2,lwd=2,lty=2)

##

#install.packages("remotes")
#remotes::install_github("goodekat/redres")
#library(redres)
#launch_redres(fit.full)
```

## Session info

```{r}
sessionInfo()
```
