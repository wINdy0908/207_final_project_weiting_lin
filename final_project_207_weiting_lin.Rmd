---
title: "final project"
author: "WEITING LIN"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

\newpage

# Abstract

The purpose of this project is to identify the critical factors that influence the number of neuron spikes and to fit a model to predict the perceptual decision of the mouse. To achieve these goals, we first use a two-way ANOVA mixed model to observe the mean firing rate across visual stimuli levels. Afterward, we use a Logistic Regression Model, also known as the Generalized Linear Model, to predict the feedback of mouse selection in each trial. Before implementing the models, we will perform Exploratory Data Analysis and conduct sensitivity analysis to check if the two models follow the assumption of homogeneity of variance and normality assumption after modeling.

# Introduction

According to the article "Distributed coding of choice, action and engagement across the mouse brain" (2019) by Steinmetz et al., perceptual decisions may involve processing sensory information, choosing an action, and carrying out actions. However, neuronal signals that relate to action do not necessarily relate to choice. For a brain region to contain choice-related signals, it must have neurons that predict the selected action before it occurs. Therefore, we believe that neural activities may play a crucial role in perceptual decisions.

To determine the distribution of neurons encoding vision, choice, action, and behavioral engagement, Steinmetz et al. and his team conducted experiments on mice to figure out the visual stimuli in response to neural activities around the mouse brain.

The motivation behind using a subset of data collected by Steinmetz et al. (2019) is to understand the correlation between visual stimuli and mouse choice and to predict if the mouse successfully predicts the result of a trial based on the contrast level of visual stimuli.

The key variables in the subset data include the levels of contrast between the right stimulus and left stimulus, the number of spikes of neurons in the visual cortex in unit time (0.4s per trial), and feedback on the trials.

In this project, our first primary objective is to determine how neurons perform in response to the visual cortex affected by two stimuli, right contrast levels and left contrast levels of mice.

Our second primary objective is to predict the outcome of each trial with neuron activities and two stimuli, which include right contrast and left contrast. The outcome of each trial will be whether the mice failed or succeeded in the trial.

To achieve our first primary objective, we will use a mixed-effect model, a two-way ANOVA, and set the stimulus from the right contrast and the stimulus from the left contrast level as fixed effects. We will set the session as a random effect since we randomly selected 5 sessions out of 39 sessions.

To achieve our second primary objective, we will use a Logistic Regression Model to predict the feedback of mouse choice, which is binary.

We believe that the discovery of the relationship between neuron activities and behavioral choice may advance the understanding of the principle of neurons that encode behaviorally relevant variables throughout the human brain.

# Background

In the study implemented by Steinmetz et al. (2019), experiments were conducted with 10 mice between 11 and 46 weeks over 39 sessions. Steinmetz et al. set up a 0.4s time interval for each trial in each session. The mouse was presented with visual stimuli on two screens positioned on either side of it during several hundred trials in each session. The presentation of stimuli was random. Additionally, the stimuli had four contrast levels {0,0.25,0.5,1}, and 0 means no stimuli.

The mouse controlled the wheels with their forepaws to decide to turn right or left or to stay still. The mouse could receive a reward if they turned the wheel to the highest contrast side. If neither stimulus occurred and the mouse kept the wheel still for 1.5s, it could also receive the reward.

During the trials, the neuronal activity from 3000 neurons in the visual cortex of the mice was recorded and provided in the form of spike trains, which are collections of timestamps corresponding to neuron firing.

In this project, we utilize subset data from Steinmetz et al. and focus on experiments of two mice, Cori and Forssmann. We have Cori's data on 12/14/2016, 12/17/2016, and 12/18/2016, and Forssmann's data on 11/01/2017,11/02/2017. Hence, there are five RDS files in this project.

The number of trials in each session is bigger than 30, so these five sessions have enough sample numbers based on the statistics requirement.

Each data session consists of the following variable:

-   **feedback_type**: type of feedback,

    -   feedback_type=1, means mouse succeeded in the trial

    -   feedback_type=-1, means mouse failed the trial

-   **contrast_left**: contrast of the left stimulus,

-   **contrast_right**: contrast of right stimulus,

-   **spks**: numbers of spikes of neurons in the visual cortex in unit time

-   **time**: centers of the time bins for spks

```{r echo=FALSE, message=FALSE, warning=FALSE}
data_list=list()
for( i in 1:5){
  file_name=paste0("session",i,".rds")
  data_list[[i]]=readRDS(file_name)}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
num_trial_in_each_file=vector()
for(i in 1:5){
  num=length(data_list[[i]]$spks)
  num_trial_in_each_file=append(num_trial_in_each_file,num)
}

trials<-data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_trials=num_trial_in_each_file)

knitr::kable(trials,align="cc",caption="Table 1: number of trials in each file ")
```

## Descriptive analysis

Trials number of each session are different (see Table 1), we have 214, 251, 228, 249, 254 trials in session Cori_12/14, session Cori_12/17, session Cori_12/18, session Forsssmann_11/01, session Forsssmann_11/01 solely.

Neurons number of each session are diverse as well (see Table 2), we have 178, 533, 228, 120, 99 neurons in session Cori_12/14, session Cori_12/17, session Cori_12/18, session Forsssmann_11/01, session Forsssmann_11/01 separately.

```{r echo=FALSE, message=FALSE, warning=FALSE}
num_of_neurons=c()
for(i in 1:5){
  num=dim(data_list[[i]]$spks[[1]])[1]
  num_of_neurons[i]=num
}

num_of_neurons_in_each_file=data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_neurons=num_of_neurons)

knitr::kable(num_of_neurons_in_each_file,align="cc",caption="Table 2: number of Neurons in each trial")
```

### Data pre-processing

Due to the neurons in each session are various (see Table two), we will take the mean firing rate, which is the average rate of neuron spikes per second in each trial.

mean firing rate in each trial:

```{=tex}
\begin{align}

\frac{\text {sum of spikes of all neourns in each trial}}{\text {(total number of neurons in each trial).(total time in 39 time intervals = 0.4s)}}

\end{align}
```
At first, we would like to check if there exists NA values in five sessions (Cori_12/14, Cori_12/17, Cori_12/18, Forssmann_11/01, Forssmann_11/02), and the result shows that it doesn't have NA value. Second, we check the structure of the data, and find that the type of feedback (feedback_type), left contrast levels(contrast_left), right contrast levels (contrast_right) variable are not factor; hence, we will transform them from numeric to factor.

Second, we combine the right contrast level and left contrast level and mean firing data of all session to crate a new data set. Therefore, we get 1196 data from the five sessions (Cori_12/14, Cori_12/17, Cori_12/18, Forssmann_11/01, Forssmann_11/02), which means that there are 1196 trials in five sessions (Cori_12/14, Cori_12/17, Cori_12/18, Forssmann_11/01, Forssmann_11/02).

```{r message=FALSE, warning=FALSE, include=FALSE}
#to check na
for(i in 1:5){
  print(any(is.na(data_list[[i]])))
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#transform data type
for(i in 1:5){
  data_list[[i]]$feedback_type<-as.factor(data_list[[i]]$feedback_type)
  data_list[[i]]$contrast_left<-as.factor(data_list[[i]]$contrast_left)
  data_list[[i]]$contrast_right<-as.factor(data_list[[i]]$contrast_right)
}

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#new data set
overall_feedback<-c(data_list[[1]]$feedback_type,data_list[[2]]$feedback_typ,data_list[[3]]$feedback_typ,data_list[[4]]$feedback_typ,data_list[[5]]$feedback_typ)

overall_left_contrast<-c(data_list[[1]]$contrast_left,data_list[[2]]$contrast_left,data_list[[3]]$contrast_left,data_list[[4]]$contrast_left,data_list[[5]]$contrast_left)

overall_right_contrast<-c(data_list[[1]]$contrast_right,data_list[[2]]$contrast_right,data_list[[3]]$contrast_right,data_list[[4]]$contrast_right,data_list[[5]]$contrast_right)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#mean firing rate in 5 session
avg_firing_rate=c()
num=1
for(i in 1:5){
  trial=length(data_list[[i]]$spks)
  for(j in 1:trial){
    neurons=dim(data_list[[i]]$spks[[j]])[1]
    avg_firing_rate[num]=sum(data_list[[i]]$spks[[j]])/neurons/0.4
    num=num+1
  }
}
```

The new data will contain 5 columns, which are feedback of a trial (feedback), contrast of the left stimulus in each trial (contrast_left), contrast of the left stimulus in each trial (contrast_right), and mean firing rate of in each trial (avg_firing_rate), and corresponding session of each trial (session).

From the plot below, we could find that distribution in average firing rate in session 5 may have Chi-squared distribution, and distributions of others are more likely to have normal distribution.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#create new data including feedback, left contrast level, right contrast leverl, average #firing rate across each trial in five files
library(ggplot2)
#install.packages("hrbrthemes")
#install.packages("rlang")
library(rlang)
library(hrbrthemes)
library(dplyr)
library(tidyr)
library(viridis)
new_data<-data.frame(feedback=overall_feedback,contrast_left=overall_left_contrast,contrast_right=overall_right_contrast,avg_firing_rate=avg_firing_rate,session=c(rep("session 1",214),rep("session 2",251),rep("session 3",228),rep("session 4",249),rep("session 5",254)))
new_data$session<-as.factor(new_data$session)
#head(new_data)
p2 <- ggplot(data=new_data, aes(x=avg_firing_rate, group=session, fill=session)) +
    geom_density(adjust=1.5, alpha=.4) +
    theme_ipsum()
p2
```

### Feedback of each session

After data pre-processing, we would like yo heck the success rate, mouse succeeded to turn the wheel to the right sides, in each session. Hence, we do some calculation on feedback. The table below (Table 3) shows that 5 sessions do not have too much difference in success rate, all of them are around 65% to 66%.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
library(pander)
#xtabs(~overall_left_contrast+overall_right_contrast,data=new_data)
new_data%>%group_by(session)%>%summarise(success_rate=paste0(round(sum(feedback==1)*100/length(feedback),2),"%"))->success
pander(success,caption="Table 3: success rate in each session",justify="center")
```

### Activities of each neuron per second in first trial and last trial among five sessions

Due to the reason the difference neurons number in five session, we would like to find out if there exists some special phenomenons in the five sessions. Hence, we plot the average firing rate of each neuron per second in the first trial and in last trial among five sessions.

average firing rate of each neuron per second per trial:

```{=tex}
\begin{align}

\frac{\text {sum of spikes for each neourn in each trial}}{\text {(total time in 39 time intervals)}}

\end{align}
```
We are curious about the activities of each neuron from each session. However, the trials in each session are numerous, which may influence the visualization of the activities of each neuron in each trail, so we only take the first trial and last trial in each session to find out if there exists special pattern of activities of neuron.

From the histogram plots below, we find out that the activities of neurons will drop down in last trail of each session, which means that the number of spikes in 0 increase. Besides, we also observe that the maximum number of spikes in first trial is bigger than the maximum one in last trial, except in session five (see Table 4). Hence, we deduce that the performance of the neuron will decrease over time. In other words, the concentration of mouse decreases over extensive trials.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
neuron_trial<-function(x,y){
  a=c()
  for(i in y){
    a=append(a,rowSums(data_list[[x]]$spks[[i]]))
  }
  return(a)
}
compare=function(x=session,y=neuron,z=trial){
  index=c(rep("last trial",y),rep("first trial",y))
  level_order=c("last trial","first trial")
  index=factor(index,level=level_order)
  newd=data.frame(index=index,firing_rate=c(neuron_trial(x,z),neuron_trial(x,1)))
  ggplot(newd, aes(x=firing_rate, color=index)) + geom_histogram(fill="white",alpha=.3,position="identity")+xlab(paste0("session",x))+ylab("neurons count")
}


first_trial=c(max(neuron_trial(1,1)),max(neuron_trial(2,1)),max(neuron_trial(3,1)),max(neuron_trial(4,1)),max(neuron_trial(5,1)))

last_trial=c(max(neuron_trial(1,214)),max(neuron_trial(2,251)),max(neuron_trial(3,228)),max(neuron_trial(4,249)),max(neuron_trial(5,254)))

session=c("session 1","session 2","session 3","session 4","session 5")

pander(data.frame(session=session,first_trial=first_trial,last_trial=last_trial),caption="Table 4 : maximum number of spikes in first trial and last trial in each session",justify="center")
```

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#require(gridExtra)
#install.packages("gridExtra")
library("gridExtra")
par(mfrow=c(3,2))
plot1<-compare(1,178,214)
plot2<-compare(2,533,251)
plot3<-compare(3,228,228)
plot4<-compare(4,120,249)
plot5<-compare(5,99,254)
grid.arrange(plot1, plot2,plot3,plot4,plot5,ncol=2)

```

### Main effect from left contrast levels and right contrast levels

We are curious about that if the same levels of contrast of two sides, left and right, have the same effect on mean firing rate of mice; therefore, we take the mean plots of two sides contrast levels over 5 sessions to discover the influence on mean firing rate.

From the figure 1, we could observe contrast of left stimulus has the highest mean firing rate when contrast level at 0.05 rather than level at 1, and has the lowest mean firing rate when contrast level at 0.25.

From the figure 2, the mean firing rate from contrast of right stimulus would have the lowest value when contrast level at 0.25, and have the highest value when contrast level at 1.

Despite the fact that both sides have the lowest mean firing rate value at level 0.25, the stimuli from both sides still have the different mean firing rate at the same contrast levels.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
library(gplots)
par(mfrow=c(1,2))
plotmeans(avg_firing_rate~contrast_left,data=new_data,xlab = "left contrast levels",ylab="mean firing rate",main="figure 1: Main effect from left contrast stimulus",cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data,xlab="right contrast levels",ylab="mean firing rate",main="figure 2: Main effect from right contrast stimulus",cex.main=0.8)
```

After taking a look at mean plots of two sides contrast levels over five sessions, we are interested in if the main effect of two sides contrast levels has the similar corresponding mean firing rate in each sessions.

From the plots below (figure 3 to figure 8), we find that the highest mean firing rate occurs when contrast level of right stimulus at 1 excluding session 1. However, the highest mean firing rate in response to left stimulus is either at contrast level 0.25 or at contrast level 0.5 in each session.

In general, the diverse effects on mean firing rate are shared by the main effects of the two stimuli presented on each side during the session.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(1,2))
for(i in 1:5){
  name=paste0("session ",i)
plotmeans(avg_firing_rate~contrast_left,data=new_data[new_data$session==name,],xlab = "left contrast levels",ylab="mean firing rate",main=paste0("figure ",i+2,": Main effect of left contrast stimulus"),cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data[new_data$session==name,],xlab="right contrast levels",ylab="mean firing rate",main=paste0("figure ",i+3,": Main effect of right contrast stimulus"),cex.main=0.8)
mtext(paste0("session",i),side = 3,line = -0.79,cex=1,outer = TRUE)
      
}

```

### Interaction effect between left side contrast levels and right side contrast levels

Due to the reason that mouse got the two sides stimuli at the same time, we consider that the interaction effect between right side contrast levels (contrast_right) and left side contrast levels (contrast_left) may affect the mean firing rate. Hence, we do interaction plot to see if the interaction effect exists.

From the figure 3, we could learn that there exists the interaction effect between left side contrast levels and right side contrast levels. Because the lines in the figure 3, combinations of left side contrast levels and right side contrast levels, cross.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
interaction.plot(new_data$contrast_left,new_data$contrast_right,new_data$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main="figure 9: interaction effect between right contrast levels and left contrast levels",cex.main=0.8)
```

We would like to determine whether there is an interaction effect between the contrast levels of the two sides in any session. Figures 10 to 14 show that the four lines in each plot intersect, indicating that each session has an interaction effect that may affect the mean firing rate.

Based on the results, we will test whether the interaction effect is significant in the interpretation of the mean firing rate in the following inferential analysis.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(2,1))
#par(mar = c(1, 1, 1, 1))
for(i in 1:5){
  name=paste0("session ",i)
  interaction.plot(new_data[new_data$session==name,]$contrast_left,new_data[new_data$session==name,]$contrast_right,new_data[new_data$session==name,]$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main=paste0("figure ",i+9,": interaction effect of session",i,": right contrast levels and left contrast levels"),cex.main=0.8)
}

```

## Inferential analysis

### Mixed effect model-Two way ANOVA

Since there is no whole plot split factor in this model, we will focus on a two-way ANOVA model with a fixed effect of the two contrast level variables and a random effect of session. We will use Type III ANOVA because we assume that the interaction effect is significant.

$Y_{ijkl}=\mu_{....}+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\gamma_l+\epsilon_{ijkl}$ i=1,2,3,4 j=1,2,3,4 k=1..$n_{ijl}$, l=1,2,3,4,5

-   $Y_{ijkl}$: refer to the $k^{th}$ mean firing rate in $l^{th}$ session across $i^{th}$ left contrast level and $j^{th}$ right contrast level.

-   $\mu_{….}$ is the overall mean firing rate across all trials in five sessions.

-   $\alpha_i$ refers to main effect of the $i^{th}$ left side contrast level, and $\alpha_i$ is fixed effect so $\sum_{i=1}^{4}\alpha_i=0$.

    -   i=1: left side contrast level=0

    -   i=2: left side contrast level=0.25

    -   i=3: left side contrast level=0.5

    -   i=4: left side contrast level=1

-   $\beta_j$ refers to main effect of the $j^{th}$ right side contrast level, and $\beta_j$ is fixed effect so $\sum_{j=1}^{4}\beta_j=0$.

    -   j=1: right side contrast level=0

    -   j=2: right side contrast level=0.25

    -   j=3: right side contrast level=0.5

    -   j=4: right side contrast level=1

-   $(\alpha\beta)_{ij}$ refers to the interaction effect between $j^{th}$ right contrast level and $i^{th}$ left contrast level, and there will be 16 kinds of combinations of two sides contrast levels.$\sum_{i=1}^{4}(\alpha\beta)_{ij}=0, \sum_{j=1}^{4}(\alpha\beta)_{ij}=0$.

-   $\gamma_l$ refers to the $l^{th}$ session, and$\gamma_l$ is random effect, $\gamma_l\sim N(0,\sigma_{\gamma})$.

    -   l=1: session 1

    -   l=2: session 2

    -   l=3: session 3

    -   l=4: session 4

    -   l=5: session 5

-   $\epsilon_{ijkl}$: refer to the residual of mean firing rate of $k^{th}$ trial in $l^{th}$ session across $i^{th}$ left contrast level and $j^{th}$ right contrast level in, $\epsilon_{ijkl}$ i.i.d $N(0,\sigma^2)$.

From the ANOVA table (Table 5) below, we can see that the interaction effect is slightly significant because its p-value, 0.04353, is less than 0.05. Moreover, the p-values for the left stimulus contrast and right stimulus contrast are 9.737x$10^{-5}$ and 4.806x$10^{-7}$, respectively.

We can also conclude that both the contrast of the right stimulus and the contrast of the left stimulus strongly influence the mean firing rate, as both of their p-values are less than 0.001. Besides, proportion of variability that is due to variability in session is 76.02%, which is calculated from $\sigma_{\gamma}/(\sigma_{\gamma}+\sigma)$.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#install.packages("car")
library("lme4")
library(pander)
#install.packages("lmerTest")
library("lmerTest")
library(car)
library(carData)
options(contrasts = c("contr.treatment", "contr.poly"))
fit.full <- lmer(avg_firing_rate ~ contrast_left+contrast_right+contrast_left*contrast_right+(1|session), data=new_data)
#summary(fit_full)
pander(anova(fit.full),caption = "Table 5: Type III Analysis of Variance Table with Satterthwaite's method (continued below)",justify="center")
#proportion=(126.67/(126.67+39.95))
```

#### Hypothesis: Reduced model versus Full model

$H_0: (\alpha\beta)_{ij}$ does not exist.

$H_1: (\alpha\beta)_{ij}$ exists.

We will use an F-test, based on the hypotheses above, to determine if there is an interaction effect between the right contrast level and the left contrast level. The result shows that the p-value is small (\<0.05) to reject the null hypothesis; therefore, we conclude that $(\alpha\beta)_{ij}$ exists. In other words, we will keep the interaction effect in the model.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(pander)
fit.reduced<-lmer(avg_firing_rate ~contrast_left+contrast_right+(1|session), data=new_data)
#(step_res <- step(fit.full))
#final <- get_model(step_res)
#a<-anova(final)
anova(fit.full,fit.reduced)
```

#### Estimated coefficients of $\alpha_i,\beta_j,(\alpha\beta)_{ij}$

Now that we have selected the full model including interaction, we will proceed to calculate the estimated coefficients of the model

$\hat \alpha_i = \bar Y_{i...}-\bar Y_{....},\space i=1,2,3,4 \\ \hat \beta_j = \bar Y_{.j..}-\bar Y_{....},\space j=1,2,3,4 \\ \widehat {(\alpha\beta)_{ij}} = \bar Y_{ij..}-(\bar Y_{....}+\hat \alpha_i+\hat \beta_j), i=1,2,3,4,\space j=1,2,3,4$

-   $\hat \alpha_i$ refers to the estimated coefficient of $i^{th}$contrast level of left stimulus,

    -   i=1: contrast level of left stimulus will be 0

    -   i=2: contrast level of left stimulus will be 0.25

    -   i=3: contrast level of left stimulus will be 0.5

    -   i=4: contrast level of left stimulus will be 1

-   $\hat \beta_j$ refers to the estimated coefficient of $j^{th}$contrast of right stimulus,

    -   j=1: contrast level of right stimulus will be 0

    -   j=2: contrast level of right stimulus will be 0.25

    -   j=3: contrast level of right stimulus will be 0.5

    -   j=4: contrast level of right stimulus will be 1

-   $\widehat {(\alpha\beta)_{ij}}$ refers to the estimated coefficient on $i^{th}$contrast of left stimulus and $j^{th}$contrast of right stimulus

From the Table 6, Table 7, Table 8, we could learn the estimated coefficients of $\alpha_i, \beta_j,(\alpha\beta)_{ij}$ across the two sides contrast levels, which contain {0,0.25,0.5,1}.

```{r echo=FALSE, message=FALSE, warning=FALSE}
contrast_left=c()
for(i in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
  contrast_left<-append(contrast_left,ans)
}

contrast_right=c()
for(j in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
  contrast_right<-append(contrast_right,ans)
}

interaction_effect=c()
for(i in c(0,0.25,0.5,1)){
  for(j in c(0,0.25,0.5,1)){
    alpha<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
    beta<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
    ans<-mean(new_data[new_data$contrast_left==i&new_data$contrast_right==j,4])-(mean(new_data$avg_firing_rate)+alpha+beta)
    interaction_effect<-append(interaction_effect,ans)
  }
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
pander(data.frame(i=c(1,2,3,4),left_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_left),caption = "Table 6: estimated alpha_i",justify="center")
pander(data.frame(j=c(1,2,3,4),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_right),caption = "Table 7: estimated beta_j",justidy="center")
pander(data.frame(i=c(rep(1,4),rep(2,4),rep(3,4),rep(4,4)),j=rep(c(1,2,3,4),4),left_contrast_level=c(rep(0,4),rep(0.25,4),rep(0.5,4),rep(1,4)),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha_beta=interaction_effect),caption = "Table 8: estimated interaction effect",justify="center")
```

### Logistics regression model

Since the feedback variable has binary outcomes, either failed (feedback=1) or succeeded (feedback=-1), we will use a logistic regression model to predict the feedback based on whether the mouse chooses the correct side with the strong contrast level.

We are also interested in determining whether the reduced model is better than the full model. The factors in the reduced model include the contrast of the right stimulus and the contrast of the left stimulus, while the full model includes all the factors in the reduced model as well as the interaction factor between the contrast of the right stimulus and the contrast of the left stimulus.

We chose not to include the average firing rate of each neuron per second across trials in the model because we know that the mouse's attentiveness decreases over trials, and using this information in the model may lead to inaccurate predictions. Additionally, the number of neurons varies across each session, so we used the mean firing rate across each session and each trial as the explanatory variable in this model.

#### Data Pre-processing

We would like to change the value of feedback because the Logistic regression model requests that the response value should be in {0,1}. As a result, we will transform the feedback value to 0 when it is -1 and keep other feedback values as 1.

Table 9 indicates the levels of feedback and the number of two levels, 0 and 1, after data pre-processing.

We also need to split our dataset into a training dataset and a testing dataset. In this part, we set the first 100 datasets as testing data and the remaining 1096 trials as the training data.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
levels(new_data$feedback)[levels(new_data$feedback)=="-1"]<-"0"
ans<-data.frame(table(new_data$feedback))
colnames(ans)<-c("level","count")
pander(ans,caption="Table 9: the levels of feedback and the corresponding numer of each level",justify="center")
train<-new_data[101:1196,]
test<-new_data[1:100,-1]
```

#### Hypothesis: Reduced model versus Full model

$H_0: \beta_{ij}=0$, for i=1,2,3,4, j=1,2,3,4

$H_1:$ at least one $\beta_{ij}\neq0$ , for i=1,2,3,4, j=1,2,3,4

$\beta_{ij}$ refer to the coefficient of interaction from $i^{th}$ level of contrast of left stimulus and $j^{th}$ level of contrast from right stimulus.

To find out which model is better we use Likelihood Ratio Test to determine the result. The result indicated that model with interaction is better, which means we will reject null hypothesis, because the p-value (0.9226x$10^{-3}$) is smaller than 0.01. Additionally, the AIC of the full model is 1380.1, which is smaller than the reduced model (whose AIC is 1390.1). Therefore, we can conclude that the full model with interaction is more appropriate.

```{r echo=FALSE, message=FALSE, warning=FALSE}
predict.full<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)

predict.reduce<-glm(feedback~contrast_left+contrast_right+avg_firing_rate,family=binomial,data=train)
#summary(predict.reduce)
anova(predict.reduce,predict.full,test="LRT")
```

The GLM model will be the formula below.

```{=tex}
\begin{align} \text{logit{P(feedback is 1)}}=\beta_0+\sum_{i=2}^{4}\beta_{1i}X_{1i}+\sum_{j=2}^{4}\beta_{2j}X_{2j}+\beta_3X_3+\sum_{i=2}^{4}\sum_{j=2}^{4}\beta_{5ij}X_{5ij}\end{align}
```
$\beta_{1i}$ represents the coefficients of $i^{th}$ left contrast level, $\beta_{2j}$ represents the coefficients of $j^{th}$ right contrast level, $\beta_3$ represents the coefficient of mean firing rate, $\beta_{5ij}$ represents the coefficient of interaction at $i^{th}$ left contrast level and $j^{th}$ right contrast level.

The corresponding contrast level of i={1,2,3,4} and j={1,2,3,4} is {0,0.25,0.5,1}.

The corresponding estimated coefficients of factors in the GLM are presented in Table 10. The reason why the estimated coefficients for contrast levels including 0, which means either i or j is denoted as 1 on each side, disappear is because we use them as a baseline for other contrast levels.Due to the positive coefficient of $X_{avg \space firing \space rate}$, we can say that the mean firing rate will have a positive influence on choosing the correct direction and increase the probability of success in a trial.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
ans<-summary(model)
#ans
result<-data.frame(ans$coefficients[,1])
colnames(result)<-"estimated coefficient"
pander(head(result,5),caption="Table 10: first 5 estimated coeffecicient of GLM model",justify="center")
```

#### Prediction

The confusion matrix will be below matrix :

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
model_train<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
threshold<-0.5
predict_value<-ifelse(predict(model_train,test)>threshold,1,0)
actual_value<-new_data$feedback[1:100]
table(predict_value,actual_value)
```

From the Table 11, it show sensitivity, specificity, and accuracy rate from the prediction result.

-   Sensitivity: also called true positive rate which is the probability of a positive test result.

    -   Formula: $\frac{True\space Positive}{True\space Positive+False\space Negative}=\frac{12}{62+12}$

-   Specificity: also known as true negative rate, which the probability of a negative test result.

    -   Formula: $\frac{True \space Negative}{True \space Negative+False\space Positive}=\frac{3}{23+3}$

-   Accuracy: refer to the probability that model predict the correct feedback.

    -   Formula: $\frac{True \space Negative+True \space Positive}{True \space Negative+True \space Positive+False\space Positive+False\space Negative}=\frac{65}{65+35}$

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
pander(data.frame(Sensitivity=paste0(round(12*100/(12+62),2),"%"),Specificity=paste0(round(300/(23+3),2),"%"),Accuracy=paste0(round(65*100/(65+35),2),"%")),caption = "Table 11",justify="center")
```

## Sensitive analysis

### Sensitive analysis for two anova model

#### Assumption: Normality

In Figure 15, the QQ-plot shows that there is a heavy tail and some outliers, which are labeled with their corresponding session. Overall, it is still obvious that the distribution of the data follows the diagonal line. Hence, we can conclude that the data is normally distributed.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#install.packages("lattice")
library(lattice)
#qqnorm(resid(fit.full))
qqmath(fit.full, id=0.05, main="figur 15: QQ-plot")#id:outlier
```

#### Outliers proportion

As a general rule, any point that is more than 3 times the mean of all the Cook's distances is considered an outlier. Hence, we will use this principle to identify outliers in the mixed model. After calculations, we found that 8.9% of the data are outliers based on the mixed model

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
cooksD <- cooks.distance(fit.full)
influential <- cooksD[(cooksD > (3 * mean(cooksD, na.rm = TRUE)))]
#influential
infp<-which(cooksD > (3 * mean(cooksD, na.rm = TRUE)))
plot(cooksD)
points(infp,cooksD[infp],pch=17,col="red",cex=1.1)
proportion_out=length(infp)/length(cooksD)
#proportion_out
```

#### Assumption: **Homogeneity of Variance**

We would like to determine whether the mixed model follows homogeneity of variance. The plot below (Figure 16) shows that the residuals are not symmetric with respect to the line y=0. Therefore, we conclude that the model violates the assumption of homogeneity of variance.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
plot(fit.full,main="figure 16: fitted value versus residual",xlab="fitted value",ylab = "residual")

```

We also examined the residual versus fitted plot in each session and found that all of them do not scatter evenly around the horizontal line (y=0), indicating that they do not follow the assumption of homogeneity of variance. However, we observed an interesting pattern in which the scatter plots tend to slope downwards slowly, especially in session five and three. Therefore, we concluded that the mouse may have drifted off when they had completed too many trials.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
#install.packages("lme4")
library(lme4)
new_data$res<-residuals(fit.full)
plot(fit.full, resid(.) ~ fitted(.) | session )

```

### Sensitive analysis for GLM model

#### Pearson residuals and deviance residuals

The purpose of this section is to ensure that the model does not have any potential lack-of-fit issues, which may arise when Pearson residuals and deviance residuals are dissimilar. The box plot below indicates that the distributions of the two residuals are similar, so there is no lack-of-fit issue.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
res.P = residuals(model, type = "pearson")
res.D = residuals(model, type = "deviance")
boxplot(cbind(res.P, res.D), names = c("Pearson", "Deviance"))
```

#### Residuals plots

The purpose is to ensure that there are no systematic patterns in the residuals. The plot below shows that the red curves are close to 0 in both plots, but there may be a quadratic pattern. Higher order terms can be added to check if this pattern exists

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(1,2))
plot(model$fitted.values, res.P, pch=16, cex=0.6, ylab='Pearson Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.P, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
plot(model$fitted.values, res.D, pch=16, cex=0.6, ylab='Deviance Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.D, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
```

#### Leverage points

We use it to find the influential points in data, and find that the influential points account for 16.87% of data points.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align="center"}
par(mfrow=c(1,1))
leverage = hatvalues(model)
plot(names(leverage), leverage, xlab="Index", type="h")
points(names(leverage), leverage, pch=16, cex=0.6)
p = length(coef(model))
n = nrow(new_data)
h=2*p/n
proportion=length(which(leverage>h))/length(leverage)
#proportion
abline(h=2*p/n,col=2,lwd=2,lty=2)
```

## Alternative methods

### Redres packages

we could use redres package to find out the residuals plot of mixed model with lmer in html.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#install.packages("remotes")
#remotes::install_github("goodekat/redres")
#library(redres)
#launch_redres(fit.full)
```

## Conclusion

We made an interesting discovery during the mixed model ANOVA analysis: the contrast of the right stimulus has a more significant effect on the neuron spikes of the mouse than the contrast of the left stimulus.

Based on the analysis above, we have learned that the neuron spikes become less active with an increasing number of trials. However, due to the lack of detailed information about the neuron type, it is difficult to perform a comprehensive cluster analysis of the neuron pattern.

We also came across a research paper by Macknik SL and Livingstone MS (1998) which suggested that "A brief visual target stimulus may be rendered invisible if it is immediately preceded or followed by another stimulus." This finding could provide a reasonable explanation for the decrease in neuron spikes observed over a large number of trials.

Therefore, if a similar experiment investigating the relationship between visual stimuli and neuron spikes were to be conducted in the future, it would be important to consider the time interval between stimuli. This could potentially lead to different results in terms of neuron spikes.

## Appendix

### Reference

1.  *Distributed coding of choice, action and engagement across the mouse brain" (2019, Steinmetz et al.)*
2.  *Neuronal correlates of visibility and invisibility in the primate visual system (1998, Macknik SL, and Livingstone MS)*
3.  STA 207 Statistical Methods for Research II, Winter 2023

### **Code**

<https://github.com/wINdy0908/207_final_project_weiting_lin/blob/main/final_project_code.R>

**Github**

<https://github.com/wINdy0908/207_final_project_weiting_lin.git>

```{r eval=FALSE, include=FALSE}
data_list=list()
for( i in 1:5){
  file_name=paste0("session",i,".rds")
  data_list[[i]]=readRDS(file_name)}

##
library(ggplot2)
num_trial_in_each_file=vector()
for(i in 1:5){
  num=length(data_list[[i]]$spks)
  num_trial_in_each_file=append(num_trial_in_each_file,num)
}

trials<-data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_trials=num_trial_in_each_file)

knitr::kable(trials,align="cc",caption="Table 1: number of trials in each file ")

##
num_of_neurons=c()
for(i in 1:5){
  num=dim(data_list[[i]]$spks[[1]])[1]
  num_of_neurons[i]=num
}

num_of_neurons_in_each_file=data.frame(session_name=c("Cori_12/14","Cori_12/17","Cori_12/18","Forssmann_11/01","Forssmann_11/02"),number_of_neurons=num_of_neurons)

knitr::kable(num_of_neurons_in_each_file,align="cc",caption="Table 2: number of Neurons in each trial")

##
#to check na
for(i in 1:5){
  print(any(is.na(data_list[[i]])))
}

##
#transform data type
for(i in 1:5){
  data_list[[i]]$feedback_type<-as.factor(data_list[[i]]$feedback_type)
  data_list[[i]]$contrast_left<-as.factor(data_list[[i]]$contrast_left)
  data_list[[i]]$contrast_right<-as.factor(data_list[[i]]$contrast_right)
}

##
#new data set
overall_feedback<-c(data_list[[1]]$feedback_type,data_list[[2]]$feedback_typ,data_list[[3]]$feedback_typ,data_list[[4]]$feedback_typ,data_list[[5]]$feedback_typ)

overall_left_contrast<-c(data_list[[1]]$contrast_left,data_list[[2]]$contrast_left,data_list[[3]]$contrast_left,data_list[[4]]$contrast_left,data_list[[5]]$contrast_left)

overall_right_contrast<-c(data_list[[1]]$contrast_right,data_list[[2]]$contrast_right,data_list[[3]]$contrast_right,data_list[[4]]$contrast_right,data_list[[5]]$contrast_right)

##
avg_firing_rate=c()
num=1
for(i in 1:5){
  trial=length(data_list[[i]]$spks)
  for(j in 1:trial){
    neurons=dim(data_list[[i]]$spks[[j]])[1]
    avg_firing_rate[num]=sum(data_list[[i]]$spks[[j]])/neurons/0.4
    num=num+1
  }
}

##
#create new data including feedback, left contrast level, right contrast leverl, average #firing rate across each trial in five files
library(ggplot2)
#install.packages("hrbrthemes")
#install.packages("rlang")
library(rlang)
library(hrbrthemes)
library(dplyr)
library(tidyr)
library(viridis)
new_data<-data.frame(feedback=overall_feedback,contrast_left=overall_left_contrast,contrast_right=overall_right_contrast,avg_firing_rate=avg_firing_rate,session=c(rep("session 1",214),rep("session 2",251),rep("session 3",228),rep("session 4",249),rep("session 5",254)))
new_data$session<-as.factor(new_data$session)
#head(new_data)
p2 <- ggplot(data=new_data, aes(x=avg_firing_rate, group=session, fill=session)) +
    geom_density(adjust=1.5, alpha=.4) +
    theme_ipsum()
p2

##
library(pander)
#xtabs(~overall_left_contrast+overall_right_contrast,data=new_data)
new_data%>%group_by(session)%>%summarise(success_rate=paste0(round(sum(feedback==1)*100/length(feedback),2),"%"))->success
pander(success,caption="Table 3: success rate in each session",justify="center")

##
neuron_trial<-function(x,y){
  a=c()
  for(i in y){
    a=append(a,rowSums(data_list[[x]]$spks[[i]]))
  }
  return(a)
}
compare=function(x=session,y=neuron,z=trial){
  index=c(rep("last trial",y),rep("first trial",y))
  level_order=c("last trial","first trial")
  index=factor(index,level=level_order)
  newd=data.frame(index=index,firing_rate=c(neuron_trial(x,z),neuron_trial(x,1)))
  ggplot(newd, aes(x=firing_rate, color=index)) + geom_histogram(fill="white",alpha=.3,position="identity")+xlab(paste0("session",x))+ylab("neurons count")
}


first_trial=c(max(neuron_trial(1,1)),max(neuron_trial(2,1)),max(neuron_trial(3,1)),max(neuron_trial(4,1)),max(neuron_trial(5,1)))

last_trial=c(max(neuron_trial(1,214)),max(neuron_trial(2,251)),max(neuron_trial(3,228)),max(neuron_trial(4,249)),max(neuron_trial(5,254)))

session=c("session 1","session 2","session 3","session 4","session 5")

pander(data.frame(session=session,first_trial=first_trial,last_trial=last_trial),caption="Table 4 : maximum number of spikes in first trial and last trial in each session",justify="center")

##
#require(gridExtra)
#install.packages("gridExtra")
library("gridExtra")
par(mfrow=c(3,2))
plot1<-compare(1,178,214)
plot2<-compare(2,533,251)
plot3<-compare(3,228,228)
plot4<-compare(4,120,249)
plot5<-compare(5,99,254)
grid.arrange(plot1, plot2,plot3,plot4,plot5,ncol=2)

##
library(gplots)
par(mfrow=c(1,2))
plotmeans(avg_firing_rate~contrast_left,data=new_data,xlab = "left contrast levels",ylab="mean firing rate",main="figure 1: Main effect from left contrast stimulus",cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data,xlab="right contrast levels",ylab="mean firing rate",main="figure 2: Main effect from right contrast stimulus",cex.main=0.8)

##
par(mfrow=c(1,2))
for(i in 1:5){
  name=paste0("session ",i)
plotmeans(avg_firing_rate~contrast_left,data=new_data[new_data$session==name,],xlab = "left contrast levels",ylab="mean firing rate",main=paste0("figure ",i+2,": Main effect of left contrast stimulus"),cex.main=0.8)
plotmeans(avg_firing_rate~contrast_right,data=new_data[new_data$session==name,],xlab="right contrast levels",ylab="mean firing rate",main=paste0("figure ",i+3,": Main effect of right contrast stimulus"),cex.main=0.8)
mtext(paste0("session",i),side = 3,line = -0.79,cex=1,outer = TRUE)
}

##
interaction.plot(new_data$contrast_left,new_data$contrast_right,new_data$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main="figure 9: interaction effect between right contrast levels and left contrast levels",cex.main=0.8)

##
par(mfrow=c(2,1))
#par(mar = c(1, 1, 1, 1))
for(i in 1:5){
  name=paste0("session ",i)
  interaction.plot(new_data[new_data$session==name,]$contrast_left,new_data[new_data$session==name,]$contrast_right,new_data[new_data$session==name,]$avg_firing_rate,ylab="mean firing rate",xlab="left contrast levels",trace.label = "right contrast levels",col=c("orange","green","red","blue"),main=paste0("figure ",i+9,": interaction effect of session",i,": right contrast levels and left contrast levels"),cex.main=0.8)
}

##
#install.packages("car")
library("lme4")
library(pander)
#install.packages("lmerTest")
library("lmerTest")
library(car)
library(carData)
options(contrasts = c("contr.treatment", "contr.poly"))
fit.full <- lmer(avg_firing_rate ~ contrast_left+contrast_right+contrast_left*contrast_right+(1|session), data=new_data)
#summary(fit_full)
pander(anova(fit.full),caption = "Table 5: Type III Analysis of Variance Table with Satterthwaite's method (continued below)",justify="center")
#proportion=(126.67/(126.67+39.95))

##
library(pander)
fit.reduced<-lmer(avg_firing_rate ~contrast_left+contrast_right+(1|session), data=new_data)
#(step_res <- step(fit.full))
#final <- get_model(step_res)
#a<-anova(final)
anova(fit.full,fit.reduced)

##
contrast_left=c()
for(i in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
  contrast_left<-append(contrast_left,ans)
}

contrast_right=c()
for(j in c(0,0.25,0.5,1)){
  ans<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
  contrast_right<-append(contrast_right,ans)
}

interaction_effect=c()
for(i in c(0,0.25,0.5,1)){
  for(j in c(0,0.25,0.5,1)){
    alpha<-mean(new_data[new_data$contrast_left==i,4])-mean(new_data$avg_firing_rate)
    beta<-mean(new_data[new_data$contrast_right==j,4])-mean(new_data$avg_firing_rate)
    ans<-mean(new_data[new_data$contrast_left==i&new_data$contrast_right==j,4])-(mean(new_data$avg_firing_rate)+alpha+beta)
    interaction_effect<-append(interaction_effect,ans)
  }
}

##
pander(data.frame(i=c(1,2,3,4),left_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_left),caption = "Table 6: estimated alpha_i",justify="center")
pander(data.frame(j=c(1,2,3,4),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha=contrast_right),caption = "Table 7: estimated beta_j",justidy="center")
pander(data.frame(i=c(rep(1,4),rep(2,4),rep(3,4),rep(4,4)),j=rep(c(1,2,3,4),4),left_contrast_level=c(rep(0,4),rep(0.25,4),rep(0.5,4),rep(1,4)),right_contrast_level=c(0,0.25,0.5,1),estimated_alpha_beta=interaction_effect),caption = "Table 8: estimated interaction effect",justify="center")

##
levels(new_data$feedback)[levels(new_data$feedback)=="-1"]<-"0"
ans<-data.frame(table(new_data$feedback))
colnames(ans)<-c("level","count")
pander(ans,caption="Table 9: the levels of feedback and the corresponding numer of each level",justify="center")
train<-new_data[101:1196,]
test<-new_data[1:100,-1]

##
predict.full<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)

predict.reduce<-glm(feedback~contrast_left+contrast_right+avg_firing_rate,family=binomial,data=train)
#summary(predict.reduce)
anova(predict.reduce,predict.full,test="LRT")

##
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
ans<-summary(model)
#ans
result<-data.frame(ans$coefficients[,1])
colnames(result)<-"estimated coefficient"
pander(head(result,5),caption="Table 10: first 5 estimated coeffecicient of GLM model",justify="center")

##
model_train<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
threshold<-0.5
predict_value<-ifelse(predict(model_train,test)>threshold,1,0)
actual_value<-new_data$feedback[1:100]
table(predict_value,actual_value)

##
pander(data.frame(Sensitivity=paste0(round(12*100/(12+62),2),"%"),Specificity=paste0(round(300/(23+3),2),"%"),Accuracy=paste0(round(65*100/(65+35),2),"%")),caption = "Table 11",justify="center")

##
#install.packages("lattice")
library(lattice)
#qqnorm(resid(fit.full))
qqmath(fit.full, id=0.05, main="figur 15: QQ-plot")#id:outlier

##
cooksD <- cooks.distance(fit.full)
influential <- cooksD[(cooksD > (3 * mean(cooksD, na.rm = TRUE)))]
#influential
infp<-which(cooksD > (3 * mean(cooksD, na.rm = TRUE)))
plot(cooksD)
points(infp,cooksD[infp],pch=17,col="red",cex=1.1)
proportion_out=length(infp)/length(cooksD)
#proportion_out

##
plot(fit.full,main="figure 16: fitted value versus residual",xlab="fitted value",ylab = "residual")

##
model<-glm(feedback~contrast_left+contrast_right+avg_firing_rate+contrast_left*contrast_right,family=binomial,data=train)
res.P = residuals(model, type = "pearson")
res.D = residuals(model, type = "deviance")
boxplot(cbind(res.P, res.D), names = c("Pearson", "Deviance"))

##
par(mfrow=c(1,2))
plot(model$fitted.values, res.P, pch=16, cex=0.6, ylab='Pearson Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.P, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
plot(model$fitted.values, res.D, pch=16, cex=0.6, ylab='Deviance Residuals', xlab='Fitted Values')
lines(smooth.spline(model$fitted.values, res.D, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')


##
par(mfrow=c(1,1))
leverage = hatvalues(model)
plot(names(leverage), leverage, xlab="Index", type="h")
points(names(leverage), leverage, pch=16, cex=0.6)
p = length(coef(model))
n = nrow(new_data)
h=2*p/n
proportion=length(which(leverage>h))/length(leverage)
#proportion
abline(h=2*p/n,col=2,lwd=2,lty=2)

##

#install.packages("remotes")
#remotes::install_github("goodekat/redres")
#library(redres)
#launch_redres(fit.full)
```

## Session info

```{r}
sessionInfo()
```
